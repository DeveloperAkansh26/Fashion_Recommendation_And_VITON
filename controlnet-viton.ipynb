{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:00:31.414154Z",
     "iopub.status.busy": "2025-07-20T21:00:31.413636Z",
     "iopub.status.idle": "2025-07-20T21:01:16.499002Z",
     "shell.execute_reply": "2025-07-20T21:01:16.498398Z",
     "shell.execute_reply.started": "2025-07-20T21:00:31.414129Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 21:00:56.958374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753045257.405109      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753045257.537593      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torchvision.transforms import transforms\n",
    "import diffusers\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, ControlNetModel, StableDiffusionControlNetPipeline, DPMSolverMultistepScheduler\n",
    "from accelerate import Accelerator\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import google.generativeai as genai\n",
    "from transformers import CLIPTextModel, CLIPTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:01:39.618211Z",
     "iopub.status.busy": "2025-07-20T21:01:39.617554Z",
     "iopub.status.idle": "2025-07-20T21:01:39.674288Z",
     "shell.execute_reply": "2025-07-20T21:01:39.673546Z",
     "shell.execute_reply.started": "2025-07-20T21:01:39.618183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"HF_Token\"] = \"\"\n",
    "login(token=os.environ[\"HF_Token\"])\n",
    "\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"\"\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "gemini = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:01:41.000184Z",
     "iopub.status.busy": "2025-07-20T21:01:40.999877Z",
     "iopub.status.idle": "2025-07-20T21:01:41.004985Z",
     "shell.execute_reply": "2025-07-20T21:01:41.004097Z",
     "shell.execute_reply.started": "2025-07-20T21:01:41.000165Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:01:42.000604Z",
     "iopub.status.busy": "2025-07-20T21:01:42.000326Z",
     "iopub.status.idle": "2025-07-20T21:01:42.004806Z",
     "shell.execute_reply": "2025-07-20T21:01:42.004262Z",
     "shell.execute_reply.started": "2025-07-20T21:01:42.000583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"stabilityai/stable-diffusion-2-base\"\n",
    "TORCH_DTYPE = torch.float16\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 2\n",
    "\n",
    "# torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Model Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:03:58.984108Z",
     "iopub.status.busy": "2025-07-20T21:03:58.983684Z",
     "iopub.status.idle": "2025-07-20T21:04:07.008280Z",
     "shell.execute_reply": "2025-07-20T21:04:07.007540Z",
     "shell.execute_reply.started": "2025-07-20T21:03:58.984076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(MODEL_ID, subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(MODEL_ID, subfolder=\"text_encoder\", torch_dtype=TORCH_DTYPE).to(device)\n",
    "text_encoder.requires_grad_(False)\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(MODEL_ID, subfolder=\"vae\", torch_dtype=TORCH_DTYPE).to(device)\n",
    "vae.requires_grad_(False)\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(MODEL_ID, subfolder=\"unet\", torch_dtype=TORCH_DTYPE).to(device)\n",
    "unet.requires_grad_(False)\n",
    "\n",
    "controlnet = ControlNetModel.from_unet(unet).to(TORCH_DTYPE).to(device)\n",
    "controlnet.controlnet_cond_embedding = nn.Conv2d(\n",
    "    in_channels=10, # New input channels for concatenated conditions\n",
    "    out_channels=controlnet.config.block_out_channels[0], # Output channels typically match first block's out_channels\n",
    "    kernel_size=1,\n",
    "    stride=1,\n",
    "    padding=0\n",
    ").to(TORCH_DTYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:02:25.817356Z",
     "iopub.status.busy": "2025-07-20T21:02:25.817116Z",
     "iopub.status.idle": "2025-07-20T21:02:25.830356Z",
     "shell.execute_reply": "2025-07-20T21:02:25.829591Z",
     "shell.execute_reply.started": "2025-07-20T21:02:25.817336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, folder_path):\n",
    "        \n",
    "        self.image = os.path.join(folder_path, \"image\")\n",
    "        self.cloth = os.path.join(folder_path, \"cloth\")\n",
    "        self.cloth_mask = os.path.join(folder_path, \"cloth-mask\")\n",
    "        self.segmentation = os.path.join(folder_path, \"image-parse-v3\")\n",
    "        self.agnostic = os.path.join(folder_path, \"agnostic-v3.2\")\n",
    "\n",
    "        self.image_names = sorted([f for f in os.listdir(self.image)])\n",
    "        self.image_names.sort(key=lambda f: int(f.split(\"_\")[0]))\n",
    "\n",
    "        self.cloth_names = sorted([f for f in os.listdir(self.cloth)])\n",
    "        self.cloth_names.sort(key=lambda f: int(f.split(\"_\")[0]))\n",
    "\n",
    "        self.cloth_mask_names = sorted([f for f in os.listdir(self.cloth_mask)])\n",
    "        self.cloth_mask_names.sort(key=lambda f: int(f.split(\"_\")[0]))\n",
    "\n",
    "        self.segmentation_names = sorted([f for f in os.listdir(self.segmentation)])\n",
    "        self.segmentation_names.sort(key=lambda f: int(f.split(\"_\")[0]))\n",
    "\n",
    "        self.agnostic_names = sorted([f for f in os.listdir(self.agnostic)])\n",
    "        self.agnostic_names.sort(key=lambda f: int(f.split(\"_\")[0]))\n",
    "    \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "        self.mask_transform = transforms.Compose([\n",
    "            transforms.Resize((64, 64), interpolation=transforms.InterpolationMode.NEAREST_EXACT),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        with open(\"/kaggle/input/prompt/generated_prompts.json\") as file:\n",
    "            self.generated_prompts = json.load(file)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 6506\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = Image.open(os.path.join(self.image, self.image_names[index]))\n",
    "        cloth = Image.open(os.path.join(self.cloth, self.cloth_names[index]))\n",
    "        cloth_mask = Image.open(os.path.join(self.cloth_mask, self.cloth_mask_names[index]))\n",
    "        segmentation = Image.open(os.path.join(self.segmentation, self.segmentation_names[index]))\n",
    "        agnostic = Image.open(os.path.join(self.agnostic, self.agnostic_names[index]))\n",
    "\n",
    "        prompt = self.generated_prompts[self.cloth_names[index]]\n",
    "        \n",
    "        text_input_ids = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids.squeeze(0)\n",
    "        \n",
    "        image = self.transform(image).to(TORCH_DTYPE).to(device)\n",
    "        cloth = self.transform(cloth).to(TORCH_DTYPE).to(device)\n",
    "        cloth_mask = self.mask_transform(cloth_mask).to(TORCH_DTYPE).to(device)\n",
    "        segmentation = self.mask_transform(segmentation).to(TORCH_DTYPE).to(device)\n",
    "        agnostic = self.transform(agnostic).to(TORCH_DTYPE).to(device)\n",
    "\n",
    "        return text_input_ids.to(device), cloth, cloth_mask, segmentation, agnostic, image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:02:25.831633Z",
     "iopub.status.busy": "2025-07-20T21:02:25.831143Z",
     "iopub.status.idle": "2025-07-20T21:02:38.285912Z",
     "shell.execute_reply": "2025-07-20T21:02:38.285197Z",
     "shell.execute_reply.started": "2025-07-20T21:02:25.831610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\"/kaggle/input/vton-hd/train\")\n",
    "test_dataset = CustomDataset(\"/kaggle/input/vton-hd/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:03:04.791386Z",
     "iopub.status.busy": "2025-07-20T21:03:04.790526Z",
     "iopub.status.idle": "2025-07-20T21:03:04.796686Z",
     "shell.execute_reply": "2025-07-20T21:03:04.796075Z",
     "shell.execute_reply.started": "2025-07-20T21:03:04.791358Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prompt', 'vton-hd']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/kaggle/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:03:05.237541Z",
     "iopub.status.busy": "2025-07-20T21:03:05.236891Z",
     "iopub.status.idle": "2025-07-20T21:03:05.241266Z",
     "shell.execute_reply": "2025-07-20T21:03:05.240431Z",
     "shell.execute_reply.started": "2025-07-20T21:03:05.237519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:03:07.363186Z",
     "iopub.status.busy": "2025-07-20T21:03:07.362421Z",
     "iopub.status.idle": "2025-07-20T21:03:07.470773Z",
     "shell.execute_reply": "2025-07-20T21:03:07.470224Z",
     "shell.execute_reply.started": "2025-07-20T21:03:07.363160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accelerator = Accelerator(mixed_precision=\"no\", gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS)\n",
    "\n",
    "# Prepare models and optimizer with Accelerator\n",
    "optimizer = torch.optim.AdamW(controlnet.parameters(), lr=LEARNING_RATE) # Only optimize ControlNet\n",
    "unet, controlnet, optimizer, train_loader, text_encoder, vae = accelerator.prepare(\n",
    "    unet, controlnet, optimizer, train_loader, text_encoder, vae\n",
    ")\n",
    "\n",
    "# Diffusion scheduler\n",
    "scheduler = DPMSolverMultistepScheduler.from_pretrained(MODEL_ID, subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T21:10:21.477408Z",
     "iopub.status.busy": "2025-07-20T21:10:21.477129Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch 1/1, Step 0, Loss: 0.3439\n",
      "Epoch 1/1, Step 10, Loss: 0.2739\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training loop with gradient anomaly detection and fault tolerance.\n",
    "Detects and skips steps with gradient issues to continue training robustly.\n",
    "\"\"\"\n",
    "\n",
    "controlnet.train()\n",
    "unet.train()\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0\n",
    "    for step, (text_input_ids, cloth_tensor, cloth_mask_tensor, segmentation_tensor, agnostic_tensor, target_img_tensor) in enumerate(train_loader):\n",
    "        with accelerator.accumulate(controlnet):\n",
    "            with torch.no_grad():\n",
    "                text_embeddings = text_encoder(text_input_ids).last_hidden_state\n",
    "                target_latents = vae.encode(target_img_tensor).latent_dist.sample() * vae.config.scaling_factor\n",
    "                cloth_latents = vae.encode(cloth_tensor).latent_dist.sample() * vae.config.scaling_factor\n",
    "                agnostic_latents = vae.encode(agnostic_tensor).latent_dist.sample() * vae.config.scaling_factor\n",
    "\n",
    "            noise = torch.randn_like(target_latents)\n",
    "            timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (target_latents.shape[0],), device=device).long()\n",
    "            noisy_latents = scheduler.add_noise(target_latents, noise, timesteps)\n",
    "\n",
    "            additional_controlnet_cond = torch.cat([\n",
    "                cloth_latents,\n",
    "                agnostic_latents,\n",
    "                cloth_mask_tensor,\n",
    "                segmentation_tensor\n",
    "            ], dim=1)\n",
    "\n",
    "            try:\n",
    "                # with torch.autograd.detect_anomaly():\n",
    "                down_block_res_samples, mid_block_res_sample = controlnet(\n",
    "                    sample=noisy_latents,\n",
    "                    timestep=timesteps,\n",
    "                    encoder_hidden_states=text_embeddings,\n",
    "                    controlnet_cond=additional_controlnet_cond,\n",
    "                    return_dict=False,\n",
    "                )\n",
    "\n",
    "                model_pred = unet(\n",
    "                    noisy_latents,\n",
    "                    timesteps,\n",
    "                    encoder_hidden_states=text_embeddings,\n",
    "                    down_block_additional_residuals=down_block_res_samples,\n",
    "                    mid_block_additional_residual=mid_block_res_sample,\n",
    "                    return_dict=False,\n",
    "                )[0]\n",
    "                \n",
    "                # print(model_pred.float())\n",
    "                loss = F.mse_loss(model_pred.float(), noise.float(), reduction=\"mean\")\n",
    "                accelerator.backward(loss)\n",
    "                accelerator.clip_grad_norm_(controlnet.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            except (RuntimeError, ValueError, FloatingPointError) as e:\n",
    "                accelerator.print(f\"Gradient anomaly at Epoch {epoch+1}, Step {step}: {e}\")\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                continue\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if accelerator.is_main_process and step % 10 == 0:\n",
    "                accelerator.print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Step {step}, Loss: {total_loss / (step+1):.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accelerator.print(f\"Epoch {epoch+1} finished. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        accelerator.wait_for_everyone()\n",
    "        torch.save(accelerator.unwrap_model(controlnet).state_dict(), f\"controlnet_epoch{epoch+1}.pth\")\n",
    "        print(f\"Saved ControlNet checkpoint for epoch {epoch+1}\")\n",
    "\n",
    "accelerator.end_training()\n",
    "print(\"\\nTraining completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6793521,
     "sourceId": 10926820,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7905348,
     "sourceId": 12523650,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
